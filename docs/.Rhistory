print("hello")
setwd("~/Documents/GitHub/film_networks/RMD")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(quanteda) #for text cleaning
library(igraph) #for creating graphs
library(visNetwork) #for visualizing graphs
source("calculatecoocstats.R") #calculate co-occurrence statistics
source("grapher.R") #create graph
source("graphervf.R") #grapher 2
source("grapherdemo.R") #other grapher
source("token_filter.R") #filter tokens
load("token.all.RData")
library(rvest)
head(token.all, 5)
#convert tokens to all lower
token.all <- tokens_tolower(token.all) #convert all tokens to lower
token.all = token.all %>% tokens_remove(c('ex/adj', 'ex/noun'))
set.seed(42) #for replication
#UPDATE - general version
#sample based on min in a decade
token.all = tokens_sample(token.all, size = 22638, replace = FALSE, prob = NULL, by = decade)
ndoc(corpus_subset(token.all, year == 1940))
token.all
ndoc(tokens(token.all, year == 1940))
ndoc(tokens(token.all))
ndoc(tokens_subset(token.all, year = 1940))
docvars(token.all)
ndoc(tokens_subset(token.all, decade = 1940))
docvars(token.all)
tokens_subset(token.all, decade = 1940)
tokens_subset(token.all, decade == 1940)
head(tokens_subset(token.all, decade == 1940), 5)
seq(1940, 2010, 10)
# show number of movies in each decade
sents_df = data.frame(decade = as.character(),
n_sents = as.numeric())
for(i in seq(1940, 2010, 10)){
n_sents = ndoc(tokens_subset(token.all, decade == 1940))
sents_t = data.frame(decade = as.character(i),
n_sents = as.numeric(n_sents))
sents_df = rbind(sents_df, sents_t)
}
# number of sentences
# words per sentence
sents_df
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(quanteda) #for text cleaning
library(igraph) #for creating graphs
library(visNetwork) #for visualizing graphs
source("calculatecoocstats.R") #calculate co-occurrence statistics
source("grapher.R") #create graph
source("graphervf.R") #grapher 2
source("grapherdemo.R") #other grapher
source("token_filter.R") #filter tokens
load("token.all.RData")
library(rvest)
head(token.all, 5)
# show number of movies in each decade
sents_df = data.frame(decade = as.character(),
n_sents = as.numeric())
for(i in seq(1940, 2010, 10)){
n_sents = ndoc(tokens_subset(token.all, decade == 1940))
sents_t = data.frame(decade = as.character(i),
n_sents = as.numeric(n_sents))
sents_df = rbind(sents_df, sents_t)
}
sents_df
# number of sentences
# words per sentence
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(quanteda) #for text cleaning
library(igraph) #for creating graphs
library(visNetwork) #for visualizing graphs
source("calculatecoocstats.R") #calculate co-occurrence statistics
source("grapher.R") #create graph
source("graphervf.R") #grapher 2
source("grapherdemo.R") #other grapher
source("token_filter.R") #filter tokens
load("token.all.RData")
library(rvest)
head(token.all, 5)
#convert tokens to all lower
token.all <- tokens_tolower(token.all) #convert all tokens to lower
token.all = token.all %>% tokens_remove(c('ex/adj', 'ex/noun'))
# show number of movies in each decade
sents_df = data.frame(decade = as.character(),
n_sents = as.numeric())
for(i in seq(1940, 2010, 10)){
n_sents = ndoc(tokens_subset(token.all, decade == 1940))
sents_t = data.frame(decade = as.character(i),
n_sents = as.numeric(n_sents))
sents_df = rbind(sents_df, sents_t)
}
sents_df
# number of sentences
# words per sentence
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(quanteda) #for text cleaning
library(igraph) #for creating graphs
library(visNetwork) #for visualizing graphs
source("calculatecoocstats.R") #calculate co-occurrence statistics
source("grapher.R") #create graph
source("graphervf.R") #grapher 2
source("grapherdemo.R") #other grapher
source("token_filter.R") #filter tokens
load("token.all.RData")
library(rvest)
head(token.all, 5)
#convert tokens to all lower
token.all <- tokens_tolower(token.all) #convert all tokens to lower
token.all = token.all %>% tokens_remove(c('ex/adj', 'ex/noun'))
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(quanteda) #for text cleaning
library(igraph) #for creating graphs
library(visNetwork) #for visualizing graphs
source("calculatecoocstats.R") #calculate co-occurrence statistics
source("grapher.R") #create graph
source("graphervf.R") #grapher 2
source("grapherdemo.R") #other grapher
source("token_filter.R") #filter tokens
load("token.all.RData")
library(rvest)
head(token.all, 5)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(quanteda) #for text cleaning
library(igraph) #for creating graphs
library(visNetwork) #for visualizing graphs
source("calculatecoocstats.R") #calculate co-occurrence statistics
source("grapher.R") #create graph
source("graphervf.R") #grapher 2
source("grapherdemo.R") #other grapher
source("token_filter.R") #filter tokens
load("token.all.RData")
library(rvest)
head(token.all, 5)
#convert tokens to all lower
token.all <- tokens_tolower(token.all) #convert all tokens to lower
token.all = token.all %>% tokens_remove(c('ex/adj', 'ex/noun'))
# show number of movies in each decade
sents_df = data.frame(decade = as.character(),
n_sents = as.numeric())
for(i in seq(1940, 2010, 10)){
n_sents = ndoc(tokens_subset(token.all, decade == 1940))
sents_t = data.frame(decade = as.character(i),
n_sents = as.numeric(n_sents))
sents_df = rbind(sents_df, sents_t)
}
sents_df
# number of sentences
# words per sentence
load("token.all.RData")
# show number of movies in each decade
sents_df = data.frame(decade = as.character(),
n_sents = as.numeric())
for(i in seq(1940, 2010, 10)){
n_sents = ndoc(tokens_subset(token.all, decade == i))
sents_t = data.frame(decade = as.character(i),
n_sents = as.numeric(n_sents))
sents_df = rbind(sents_df, sents_t)
}
sents_df
# number of sentences
# words per sentence
geom_bar(stat = 'identity)
ggplot(sents_df, aes(x = decade, n_sents)) +
geom_bar(stat = 'identity'))
ggplot(sents_df, aes(x = decade, n_sents)) +
geom_bar(stat = 'identity'))
ggplot(sents_df, aes(x = decade, n_sents)) +
geom_bar(stat = 'identity')
ggplot(sents_df, aes(x = decade, n_sents)) +
geom_bar(stat = 'identity') +
theme_minimal()
ggplot(sents_df, aes(x = decade, n_sents)) +
geom_bar(stat = 'identity') +
theme_classic()
geom_bar(stat = 'identity', fill = 'black) +
ggplot(sents_df, aes(x = decade, n_sents)) +
geom_bar(stat = 'identity', fill = 'black') +
ggplot(sents_df, aes(x = decade, n_sents)) +
geom_bar(stat = 'identity', fill = 'black') +
theme_classic()
ggplot(sents_df, aes(x = decade, n_sents)) +
geom_bar(stat = 'identity', fill = 'black') +
theme_classic() + ylab('no. of sentences')
ggplot(sents_df, aes(x = decade, n_sents)) +
geom_bar(stat = 'identity', fill = 'black') +
theme_dark() + ylab('no. of sentences')
ggplot(sents_df, aes(x = decade, n_sents)) +
geom_bar(stat = 'identity') +
theme_dark() + ylab('no. of sentences')
ggplot(sents_df, aes(x = decade, n_sents)) +
geom_bar(stat = 'identity') +
theme_void() + ylab('no. of sentences')
ggplot(sents_df, aes(x = decade, n_sents)) +
geom_bar(stat = 'identity') +
theme_linerdaw() + ylab('no. of sentences')
ggplot(sents_df, aes(x = decade, n_sents)) +
geom_bar(stat = 'identity') +
theme_linedraw() + ylab('no. of sentences')
ggplot(sents_df, aes(x = decade, n_sents)) +
geom_bar(stat = 'identity', size = 3) +
theme_linedraw() + ylab('no. of sentences')
ggplot(sents_df, aes(x = decade, n_sents)) +
geom_bar(stat = 'identity', size = 1) +
theme_linedraw() + ylab('no. of sentences')
ggplot(sents_df, aes(x = decade, n_sents)) +
geom_bar(stat = 'identity', width = 0.2) +
theme_linedraw() + ylab('no. of sentences')
ggplot(sents_df, aes(x = decade, n_sents)) +
geom_bar(stat = 'identity', width = 0.2, position = position_dodge()) +
theme_linedraw() + ylab('no. of sentences')
ggplot(sents_df, aes(x = decade, n_sents)) +
geom_bar(stat = 'identity', width = 0.2) +
theme_linedraw() + ylab('no. of sentences')
ggplot(sents_df, aes(x = decade, n_sents)) +
geom_bar(stat = 'identity', width = 0.2, position = position_dodge(width = 0.9)) +
theme_linedraw() + ylab('no. of sentences')
ggplot(sents_df, aes(x = decade, n_sents)) +
geom_bar(stat = 'identity', width = 0.2, position = position_dodge(width = 0.2)) +
theme_linedraw() + ylab('no. of sentences')
ggplot(sents_df, aes(x = decade, n_sents)) +
geom_bar(stat = 'identity', width = 0.2, position = position_dodge(width = 2)) +
theme_linedraw() + ylab('no. of sentences')
ggplot(sents_df, aes(x = decade, n_sents)) +
geom_bar(stat = 'identity', width = 0.8, position = position_dodge(width = 2)) +
theme_linedraw() + ylab('no. of sentences')
ggplot(sents_df, aes(x = decade, n_sents)) +
geom_bar(stat = 'identity', width = 0.8, position = position_dodge(width = 0.9)) +
theme_linedraw() + ylab('no. of sentences')
ggplot(sents_df, aes(x = decade, n_sents)) +
geom_bar(stat = 'identity', width = 0.8,
position = position_dodge(width = 0.4)) +
theme_linedraw() + ylab('no. of sentences')
ggplot(sents_df, aes(x = decade, n_sents)) +
geom_bar(stat = 'identity', width = 0.5,
position = position_dodge(width = 0.4)) +
theme_linedraw() + ylab('no. of sentences')
geom_bar(stat = 'identity', width = 0.5, color = 'black
ggplot(sents_df, aes(x = decade, n_sents)) +
geom_bar(stat = 'identity', width = 0.5, color = 'black'
ggplot(sents_df, aes(x = decade, n_sents)) +
geom_bar(stat = 'identity', width = 0.5, color = 'black'
position = position_dodge(width = 0.4)) +
ggplot(sents_df, aes(x = decade, n_sents)) +
geom_bar(stat = 'identity', width = 0.5, color = 'black',
position = position_dodge(width = 0.4)) +
theme_linedraw() + ylab('no. of sentences')
words_df = data.frame(decade = as.character(),
n_words = as.numeric())
for(i in seq(1940, 2010, 10)){
n_words = ntoken(tokens_subset(token.all, decade == i))
words_t = data.frame(decade = as.character(i),
n_words = as.numeric(n_words))
words_df = rbind(words_df, words_t)
}
words_df
words_df = data.frame(decade = as.character(),
n_words = as.numeric())
for(i in seq(1940, 2010, 10)){
n_words = ntoken(tokens_subset(token.all, decade == i))
words_t = data.frame(decade = as.character(i),
n_words = as.numeric(n_words))
words_df = rbind(words_df, words_t)
}
words_df
ntoken(tokens_subset(token.all, decade == i))
sum(ntoken(tokens_subset(token.all, decade == i)))
for(i in seq(1940, 2010, 10)){
n_words = sum(ntoken(tokens_subset(token.all, decade == i)))
words_t = data.frame(decade = as.character(i),
n_words = as.numeric(n_words))
words_df = rbind(words_df, words_t)
}
words_df
words_df = data.frame(decade = as.character(),
n_words = as.numeric())
for(i in seq(1940, 2010, 10)){
n_words = sum(ntoken(tokens_subset(token.all, decade == i)))
words_t = data.frame(decade = as.character(i),
n_words = as.numeric(n_words))
words_df = rbind(words_df, words_t)
}
words_df
words_df$wordspsents = words_df$n_words/sents_df$n_sents
ggplot(sents_df, aes(x = decade, wordspsents)) +
geom_bar(stat = 'identity', width = 0.5, color = 'black',
position = position_dodge(width = 0.4)) +
theme_linedraw() + ylab('words per sentence')
ggplot(words_df, aes(x = decade, wordspsents)) +
geom_bar(stat = 'identity', width = 0.5, color = 'black',
position = position_dodge(width = 0.4)) +
theme_linedraw() + ylab('words per sentence')
setwd("~/Documents/GitHub/film_networks")
setwd("~/Documents/GitHub/film_networks/docs")
knitr::opts_chunk$set(echo = TRUE)
#theme: united
#highlight: tango
plot(graph_demo)
#add shiny toggle secondary, shiny toggle nodes
graph_demo = grapherdemo(5, token_filter3('all', 1940, 2020, token.all))
g_demo = graph_demo[[1]]
plot(graph_demo)
plot(g_demo)
#visIgraph(g_demo)
plot(g_demo, vertex.label = NA)
#visIgraph(g_demo)
plot(g_demo, vertex.label = NA, edge.curved=FALSE)
#visIgraph(g_demo)
plot(g_demo, vertex.label = NA, edge.curved=FALSE, layout =  layout.fruchterman.reingold)
#visIgraph(g_demo)
plot(g_demo, vertex.label = NA, edge.curved=FALSE, layout =  layout.fruchterman.reingold)
#visIgraph(g_demo)
plot(g_demo, vertex.label = NA, edge.curved=FALSE, layout =  layout.fruchterman.reingold)
#visIgraph(g_demo)
plot(g_demo, vertex.label = NA, edge.curved=FALSE)
tkplot(g_demo)
coords <- tkplot.getcoords(1)
plot(g_demo, vertex.label = NA, edge.curved=FALSE, layout = coords)
coords_demo <- tkplot.getcoords(1)
save(coords_demo)
save(coords_demo, 'coords_demo.RData')
saveRDS(coords_demo, 'coords_demo.rds')
readRDS('coords_demo.rds)
readRDS('coords_demo.rds')
readRDS(file= 'coords_demo.rds')
save(coords_demo, 'coords_demo.RData')
coords_demo <- tkplot.getcoords(1)
save(coords_demo, 'coords_demo.RData')
save(coords_demo, file = 'coords_demo.RData')
load(file= 'coords_demo.RData')
plot(g_demo, vertex.label = NA, edge.curved=FALSE, layout = coords)
plot(g_demo, edge.curved=FALSE, layout = coords)
plot(g_demo, vertex.label.size = 1, edge.curved=FALSE, layout = coords)
plot(g_demo, vertex.label.cex = 1, edge.curved=FALSE, layout = coords)
plot(g_demo, vertex.label.cex = 0.5, edge.curved=FALSE, layout = coords)
plot(g_demo, vertex.label.cex = 0.6, edge.curved=FALSE, layout = coords)
coords_demo <- tkplot.getcoords(1)
save(coords_demo, file = 'coords_demo.RData')
load(file= 'coords_demo.RData')
plot(g_demo, vertex.label.cex = 0.6, edge.curved=FALSE, layout = coords)
coords_demo <- tkplot.getcoords(1)
save(coords_demo, file = 'coords_demo.RData')
load(file= 'coords_demo.RData')
plot(g_demo, vertex.label.cex = 0.6, edge.curved=FALSE, layout = coords)
coords_demo <- tkplot.getcoords(1)
coords_demo <- tkplot.getcoords(1)
save(coords_demo, file = 'coords_demo.RData')
load(file= 'coords_demo.RData')
plot(g_demo, vertex.label.cex = 0.6, edge.curved=FALSE, layout = coords_demo)
coords_demo <- tkplot.getcoords(1)
save(coords_demo, file = 'coords_demo.RData')
load(file= 'coords_demo.RData')
plot(g_demo, vertex.label.cex = 0.6, edge.curved=FALSE, layout = coords_demo)
plot(g_demo, vertex.label.cex = 0.6, vertex.label.dist = 0.2, edge.curved=FALSE, layout = coords_demo)
plot(g_demo, vertex.label.cex = 0.6, vertex.label.dist = 0.5, edge.curved=FALSE, layout = coords_demo)
plot(g_demo, vertex.label.cex = 0.6, vertex.label.dist = 1, edge.curved=FALSE, layout = coords_demo)
plot(g_demo, vertex.label.cex = 0.6, vertex.label.dist = -1, edge.curved=FALSE, layout = coords_demo)
plot(g_demo, vertex.label.cex = 0.6, vertex.label.dist = -1.3, edge.curved=FALSE, layout = coords_demo)
plot(g_demo, vertex.label.cex = 0.6, vertex.label.dist = -1.8, edge.curved=FALSE, layout = coords_demo)
plot(g_demo, vertex.label.cex = 0.6, vertex.label.dist = -2, edge.curved=FALSE, layout = coords_demo)
plot(g_demo, vertex.label.cex = 0.6, vertex.label.dist = -2.3, edge.curved=FALSE, layout = coords_demo)
plot(g_demo, vertex.label.cex = 0.6, vertex.label.dist = 0, edge.curved=FALSE, layout = coords_demo)
#add shiny toggle secondary, shiny toggle nodes
graph_demo = grapherdemo(5, token_filter3('all', 1940, 2020, token.all))
g_demo = graph_demo[[1]]
#visIgraph(g_demo)
plot(g_demo, vertex.label = NA, edge.curved=FALSE)
#tkplot(g_demo)
#coords_demo <- tkplot.getcoords(1)
#save(coords_demo, file = 'coords_demo.RData')
load(file= 'coords_demo.RData')
plot(g_demo, vertex.label.cex = 0.6, vertex.label.dist = 0, edge.curved=FALSE, layout = coords_demo)
```{r, fig.width = 4, fig.height = 4, dpi= 200}
#add shiny toggle secondary, shiny toggle nodes
graph_demo = grapherdemo(5, token_filter3('all', 1940, 2020, token.all))
g_demo = graph_demo[[1]]
#visIgraph(g_demo)
plot(g_demo, vertex.label = NA, edge.curved=FALSE)
#tkplot(g_demo)
#coords_demo <- tkplot.getcoords(1)
#save(coords_demo, file = 'coords_demo.RData')
load(file= 'coords_demo.RData')
plot(g_demo, vertex.label.cex = 0.6, vertex.label.dist = 0, edge.curved=FALSE, layout = coords_demo)
#add shiny toggle secondary, shiny toggle nodes
graph_demo = grapherdemo(5, token_filter3('all', 1940, 2020, token.all))
g_demo = graph_demo[[1]]
#visIgraph(g_demo)
plot(g_demo, vertex.label = NA, edge.curved=FALSE)
#tkplot(g_demo)
#coords_demo <- tkplot.getcoords(1)
#save(coords_demo, file = 'coords_demo.RData')
load(file= 'coords_demo.RData')
plot(g_demo, vertex.label.cex = 0.6, vertex.label.dist = 0, edge.curved=FALSE, layout = coords_demo)
graph = grapherdemo(21, token_filter3('all', 1940, 2020, token.all)) #create graph
graph = grapherdemo(21, token_filter3('all', 1940, 2020, token.all)) #create graph
graph = grapherdemo(21, token_filter3('all', 1940, 2020, token.all)) #create graph
